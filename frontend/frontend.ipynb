{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flask tensorflow resampy librosa opencv-python pydub matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('./model/cnn_very_old.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import io\n",
    "import base64\n",
    "\n",
    "HOP_LENGTH = 512        # number of samples between successive frames\n",
    "WINDOW_LENGTH = 512     # length of the window in samples\n",
    "N_MEL = 128             # number of Mel bands to generate\n",
    "\n",
    "\n",
    "def spectrogram_fixed_length(audio, rate, total_samples = 128) -> ndarray:\n",
    "    spectrogram = librosa.feature.melspectrogram(\n",
    "        y = audio, \n",
    "        sr=rate, \n",
    "        hop_length=HOP_LENGTH, \n",
    "        win_length=WINDOW_LENGTH,\n",
    "        n_fft=512\n",
    "    )\n",
    "\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "    spectrogram_length = spectrogram_db.shape[1]\n",
    "\n",
    "    if spectrogram_length != total_samples:\n",
    "        spectrogram_db = librosa.util.fix_length(\n",
    "            spectrogram_db, size=total_samples, axis=1,\n",
    "        )\n",
    "    \n",
    "    return spectrogram_db\n",
    "\n",
    "\n",
    "def generate_spectrogram(audio, sample_rate):\n",
    "    spectrogram = spectrogram_fixed_length(audio, sample_rate)\n",
    "    librosa.display.specshow(spectrogram, cmap='viridis')\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"uploads/spectrogram.png\", bbox_inches=\"tight\", pad_inches=0.0)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: use sliding window\n",
    "def preprocess_audio(audio):\n",
    "    DURATION = 3\n",
    "    audio, sample_rate = librosa.load(audio, duration=DURATION, res_type='kaiser_fast')\n",
    "    generate_spectrogram(audio, sample_rate)\n",
    "   \n",
    "    IMG_SIZE = 256\n",
    "\n",
    "    img_array = cv.imread(\"uploads/spectrogram.png\")\n",
    "    new_array = cv.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return np.array(new_array).reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import io\n",
    "import base64\n",
    "\n",
    "HOP_LENGTH = 512        # number of samples between successive frames\n",
    "WINDOW_LENGTH = 512     # length of the window in samples\n",
    "N_MEL = 128             # number of Mel bands to generate\n",
    "WINDOW_STRIDE_SECONDS = 1    # Stride for the sliding window\n",
    "\n",
    "def spectrogram_fixed_length(audio, rate, total_samples = 128) -> ndarray:\n",
    "    spectrogram = librosa.feature.melspectrogram(\n",
    "        y = audio, \n",
    "        sr=rate, \n",
    "        hop_length=HOP_LENGTH, \n",
    "        win_length=WINDOW_LENGTH,\n",
    "        n_fft=512,\n",
    "    )\n",
    "\n",
    "    spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "    spectrogram_length = spectrogram_db.shape[1]\n",
    "    print(spectrogram_length)\n",
    "\n",
    "    if spectrogram_length != total_samples:\n",
    "        spectrogram_db = librosa.util.fix_length(\n",
    "            spectrogram_db, size=total_samples, axis=1,\n",
    "        )\n",
    "    \n",
    "    return spectrogram_db\n",
    "\n",
    "def generate_spectrogram(audio, sample_rate, output_path):\n",
    "    spectrogram = spectrogram_fixed_length(audio, sample_rate)\n",
    "    librosa.display.specshow(spectrogram, cmap='viridis')\n",
    "\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\", pad_inches=0.0)\n",
    "    plt.close()\n",
    "\n",
    "def preprocess_audio(audio):\n",
    "    DURATION = 10  # Process 10 seconds of audio\n",
    "    audio, sample_rate = librosa.load(audio, duration=DURATION, res_type='kaiser_fast')\n",
    "    DURATION = int(min(len(audio) / sample_rate, DURATION))\n",
    "\n",
    "    spectrograms = []\n",
    "\n",
    "    for window in range(DURATION):\n",
    "        output_path = f\"uploads/spectrogram_{window}.png\"\n",
    "        generate_spectrogram(audio[window * sample_rate:], sample_rate, output_path)\n",
    "        \n",
    "        img_array = cv.imread(output_path)\n",
    "        new_array = cv.resize(img_array, (256, 256))\n",
    "        print(\"reshaping\")\n",
    "        spectrograms.append(np.array(new_array).reshape(-1, 256, 256, 3) / 255)\n",
    "\n",
    "\n",
    "    # print(\"Done!\")\n",
    "\n",
    "    return spectrograms\n",
    "    # return np.array(new_array).reshape(-1, 256, 256, 3) / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_audio(\"../untitled.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, session\n",
    "\n",
    "# import os\n",
    "# from pydub import AudioSegment\n",
    "\n",
    "app = Flask(\"Audio Classifier\")\n",
    "app.config['UPLOAD_FOLDER'] = 'uploads/'\n",
    "app.secret_key = '123456'\n",
    "\n",
    "LABELS = [\n",
    "    \"air_conditioner\",\n",
    "    \"car_horn\",\n",
    "    \"children_playing\",\n",
    "    \"dog_bark\",\n",
    "    \"drilling\",\n",
    "    \"engine_idling\",\n",
    "    \"gun_shot\",\n",
    "    \"jackhammer\",\n",
    "    \"siren\",\n",
    "    \"street_music\"\n",
    "]\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    threshold = int(session.get('threshold', 0))\n",
    "    selected_categories = [int(x) for x in session.get('selected_categories', [])]\n",
    "\n",
    "\n",
    "    return render_template(\n",
    "        './index.html', \n",
    "        categories=LABELS,\n",
    "        threshold=threshold, \n",
    "        selected_categories=selected_categories\n",
    "    )\n",
    "\n",
    "\n",
    "@app.route('/process_categories', methods=['POST'])\n",
    "def process_categories():\n",
    "    selected_categories = request.get_json().get(\"selected_categories\", [])\n",
    "    # convert them to integers\n",
    "    selected_categories = [int(x) for x in selected_categories]\n",
    "\n",
    "    threshold = request.get_json().get('threshold', 50)\n",
    "\n",
    "    session['selected_categories'] = selected_categories\n",
    "    session['threshold'] = threshold\n",
    "\n",
    "    return {\"success\": True}\n",
    "\n",
    "\n",
    "@app.route('/classify', methods=['POST'])\n",
    "def classify():\n",
    "    # Get the audio file from the request\n",
    "    audio_file = request.files['audio_file']\n",
    "\n",
    "    # Process the audio file using your trained model\n",
    "    audio_data = preprocess_audio(audio_file)\n",
    "    predictions = []\n",
    "    for audio_datum in audio_data:\n",
    "        print(\"predicting...\")\n",
    "        \n",
    "        prediction = model.predict(audio_datum)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "    prediction = prediction[0]\n",
    "    # categories to include\n",
    "    selected_categories = session.get('selected_categories', [])\n",
    "    confidence_threshold = float(session.get('threshold', 0.))\n",
    "\n",
    "    p = {}\n",
    "    pred = prediction.flatten()\n",
    "\n",
    "    print(pred)\n",
    "    for (index, label) in enumerate(LABELS):\n",
    "        if index not in selected_categories:\n",
    "            continue\n",
    "\n",
    "        confidence = float(pred[index] * 100.0)\n",
    "\n",
    "        if confidence < confidence_threshold:\n",
    "            continue\n",
    "\n",
    "        p[label] = confidence\n",
    "\n",
    "    print(\"labels:\", p)\n",
    "\n",
    "    print(selected_categories)\n",
    "    print(confidence_threshold)\n",
    "\n",
    "\n",
    "    # create a predicted label\n",
    "    if len(p) == 0:\n",
    "        if len(selected_categories) == 0:\n",
    "            predicted = \"None Found. You must select a nuisance.\"\n",
    "        else:\n",
    "            predicted = \"None Found. Try lowering the detection threshold.\"\n",
    "    else:\n",
    "        predicted = max(p, key=p.get)\n",
    "\n",
    "\n",
    "    # create spectrogram image\n",
    "    file = open(\"uploads/spectrogram_0.png\", 'rb')\n",
    "    image_buffer = file.read()\n",
    "    spectrogram = base64.b64encode(image_buffer).decode('utf-8')\n",
    "\n",
    "    \n",
    "\n",
    "    # mp3_bytes = io.BytesIO()\n",
    "    # audio = AudioSegment.from_file(audio_file.read())\n",
    "    # audio.export(mp3_bytes, format='mp3')\n",
    "    # # mp3_data = mp3_bytes.getvalue()\n",
    "    \n",
    "    # audio_data = base64.b64encode(mp3_bytes.read()).decode('utf-8')\n",
    "    \n",
    "    # Return the classification result\n",
    "    return {\n",
    "        'prediction': predicted,\n",
    "        'spectrogram': spectrogram, \n",
    "        # 'audio': audio_data,\n",
    "        # 'audio_mime': audio_file.mimetype,\n",
    "        'predictions': p,\n",
    "    }\n",
    "\n",
    "app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
